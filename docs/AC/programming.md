# **Welcome to Processing!**
Processing is a flexible software sketchbook and a language for learning how to code. Since 2001, Processing has promoted software literacy within the visual arts and visual literacy within technology. There are tens of thousands of students, artists, designers, researchers, and hobbyists who use Processing for learning and prototyping.
# **How to download and install!**

**Steps:**

- Visit the official Processing website: <https://processing.org/>

- Choose the appropriate version of Processing for your operating system (Windows, macOS, or Linux).
- Click on the download link for your operating system, and the download should start automatically. 
 
 <img style="float: center;" width=100% src="image/prd.jpg">

- Once the download is finished, locate the downloaded file and extract its contents to a convenient location on your computer.
- On Windows: Right-click on the ZIP file and select "Extract All..." to extract the contents.
- On macOS: Double-click the ZIP file to extract its contents.
- On Linux: Open a terminal, navigate to the directory containing the downloaded file, and use the unzip command. 
- Open the extracted folder, and you should find the Processing application file within it. The filename varies based on the operating system:
- On Windows: Look for "processing.exe."
- On macOS: Look for "Processing.app." It may appear as an application bundle.
- On Linux: Look for "processing" (without a file extension) and make sure it has execute permissions.
- Double-click on the Processing application file to launch the Processing IDE (Integrated Development Environment).

Description of each menu

**File:**

New: Create a new sketch.

Open: Open an existing sketch.

Open Recent: Access recently opened sketches.

Save: Save the current sketch.

Save As: Save the current sketch with a new name or location.

Export: Export the sketch as an application or other formats.

Preferences: Access and modify the Processing IDE preferences.

Quit: Quit the Processing IDE.

**Edit:**

Undo: Undo the last action.

Redo: Redo the previously undone action.

Cut: Cut the selected code or text.

Copy: Copy the selected code or text.

Paste: Paste the copied or cut code or text.

Select All: Select all the code or text in the current editor.

Find: Search for specific text within the current editor.

Find Next: Find the next occurrence of the searched text.

Find Previous: Find the previous occurrence of the searched text.

Replace: Replace specific text within the current editor.

Go To Line: Jump to a specific line number in the current editor.

**Sketch:**

Run/Stop: Run or stop the current sketch.

Present: Run the sketch in full-screen presentation mode.

Import Library: Import external libraries to extend Processing's functionality.

Add File: Add files (images, sounds, data) to the sketch.

Export Application: Export the sketch as a standalone application.

Export Library: Create a library from the current sketch.

**Tools:**

Auto Format: Automatically format the code for better readability.

Tidy Up: Rearrange the code layout for better organization.

Fix Imports: Organize and manage imported libraries.

Show Sketch Folder: Open the sketch folder in the file explorer.

Color Selector: Access a color picker tool.

Create Font: Create a custom font for drawing text.

External Tools: Configure and access external tools.

**Sketchbook:**

Show Sketchbook: Open the sketchbook folder in the file explorer.

Add Folder: Add a new folder to the sketchbook.

Import Library: Import external libraries to the sketchbook.

Import Toolbox: Import toolboxes to the sketchbook.

**Help:**

Help: Open the Processing documentation in a web browser.

Reference: Open the reference documentation for Processing.

Examples: Access a collection of example sketches.

Tutorials: Access tutorials to learn Processing.

Forum: Open the Processing forum in a web browser.

Find in Reference: Search for specific terms in the reference.

Report Bug: Report a bug or issue with Processing.

Donate: Contribute to the Processing project.

**Features of Processing programming language!**

The Processing language is a powerful and popular programming language specifically designed for visual arts, creative coding, and interactive media projects. Some features of  Processing language are :

**Simplicity:**

` `Processing has a simplified syntax and a small set of core functions, making it easy to learn and use, particularly for beginners or those without a programming background. The language focuses on providing a straightforward and intuitive environment for creative expression.

**Graphics and Visualization:**

Processing excels in graphics and visualization capabilities. It provides built-in functions and libraries for creating 2D and 3D graphics, animations, interactive visualizations, and generative art. It allows users to manipulate shapes, colors, images, and pixels to create visually compelling experiences.

**Interactivity:**

Processing enables the creation of interactive applications and installations. It supports user input from various sources, such as mouse, keyboard, touch, and sensors, allowing users to build projects with interactive elements that respond to user actions or external input.

**Cross-platform:**

Processing is compatible with multiple operating systems, including Windows, macOS, and Linux, ensuring that projects can be developed and deployed across different platforms without significant modifications.

**Community and Resources:**

Processing has a large and active community of artists, designers, educators, and programmers who contribute to its growth and provide support. The community shares libraries, examples, and tutorials, making it easier to learn and expand the capabilities of the language.

**Educational Tool:** 

Processing is widely used in educational settings to introduce programming concepts and computational thinking to students. Its visual and interactive nature makes it engaging and accessible for learners of all ages. It encourages creativity and experimentation while teaching fundamental programming principles.

**Extensibility:** 

Processing supports the use of external libraries, allowing users to extend its functionality. There is a vast collection of community-contributed libraries available, covering areas such as computer vision, sound processing, physical computing, and more. This extensibility enables users to leverage existing tools and resources to enhance their projects.

**Open Source:** 

Processing is an open-source project, which means its source code is freely available and can be modified. This openness fosters collaboration, innovation, and customization, as users can contribute to the language's development and tailor it to their specific needs.

` `**Application areas:**

**Creative Coding and Digital Art:** 

Processing is widely used by artists, designers, and creative coders to create interactive installations, digital art, visualizations, and multimedia experiences. Its graphics capabilities, interactivity, and simplicity make it a popular choice for expressing artistic ideas through code.

**Data Visualization:**

` `Processing is utilized for creating visually compelling and interactive data visualizations. Its ability to render graphics and handle user input allows for the exploration and representation of complex data sets in a visual and intuitive manner.

**Education:** 

Processing is extensively used in educational settings to teach programming, computational thinking, and creative problem-solving. Its simplicity and visual nature make it accessible for learners of all ages, helping them grasp programming concepts and engage in hands-on learning experiences.

**Prototyping and Rapid Development:** 

Processing is employed for rapid prototyping and development of interactive applications and user interfaces. Its quick setup, visual feedback, and interactivity enable developers to iterate and experiment efficiently during the early stages of a project.

**Game Development:** 

While not specifically designed as a game development framework, Processing can be used to create 2D games and prototypes. Its graphics capabilities, input handling, and interactivity allow developers to build simple to moderately complex games.

**Physical Computing and Interaction Design:** 

Processing is often combined with hardware platforms like Arduino to create interactive installations, physical computing projects, and tangible user interfaces. It enables the integration of sensors, actuators, and other physical components with code to build interactive and responsive systems.

**Computational Design and Generative Art:** 

Processing is favoured by computational designers and artists for generative art projects. It provides tools and libraries for creating algorithmic and rule-based art, where the code generates visual or auditory output based on predefined rules or randomization.

**Sound and Music:** 

Processing supports audio processing and synthesis, making it suitable for creating interactive sound installations, music visualizations, and live performances. It provides libraries for working with sound files, MIDI, and real-time audio manipulation.
## **Fundamentals of Processing!**
The Processing code is comprised of two essential sections: setup and draw blocks. The setup block initiates once upon code execution, while the draw block operates continuously. In Processing, the core concept is that code within the draw block executes 60 times per second, sequentially from top to bottom, until program termination. Leveraging this idea, you can create dynamic elements, manage scores, detect collisions, implement gravity, and handle various functionalities. This continuous execution, known as the refresh loop, serves as the vital pulse of your project. Subsequent sections will elaborate on harnessing this heartbeat to animate your code. Initially, let me introduce you to the Processing IDE.
### **Processing IDE!**

<img style="float: center;" width=100% src="image/idi.jpg">

The anticipated functionalities of the run and stop buttons are as expected. Upon clicking the run button, your code undergoes compilation and execution. In the inherent nature of Processing programs, they persist indefinitely, running continuously until deliberately interrupted. While it is possible to programmatically terminate the execution, the stop button provides a convenient manual option.

The butterfly-shaped button situated to the right of the run and stop buttons represents the debugger. Delving into the usage of the debugger requires a dedicated article, exceeding the current scope. Consequently, it is advisable to disregard it for the present. The dropdown menu adjacent to the debugger button is where you incorporate or configure mods. Mods furnish specific functionalities, enabling you to write code for Android, use Python, and more. As mods are beyond the current scope, it is recommended to maintain the default Java mode and overlook this feature.

The console, depicted as a black box below, serves as a tool for swiftly printing information during the debugging process. The errors tab, positioned alongside the console, is a valuable addition introduced in Processing 3.0. In previous versions, errors were directed to the console, making it challenging to manage and track them effectively.
### **Setup Block**
As mentioned earlier, setup blocks are executed once at the beginning of the program. This block is suitable for configurations and tasks intended to run only once, such as loading images or sounds. Below is an illustrative setup block example. Feel free to execute this code in your local environment to observe the outcomes.

        public void setup() {

    // The size of our sketch will be 800x600, 
    // and it will use the P2D rendering engine.
    size(800, 600, P2D);

    // Alternatively, we could have used fullScreen(P2D).

    // The background color of our sketch will be black by default, unless specified otherwise.
    background(0);

    // We could have used the following to set a background image.
    // Note that the size of our sketch should be the same as the image.
    // background(loadImage("test.jpg"));

    // Shapes and objects will be filled with red by default, unless specified otherwise.
    fill(255, 0, 0);

    // Shapes and objects will have a white border by default, unless specified otherwise.
    stroke(255);
    }

The methods related to styling (background, fill, stroke) will be explained in the properties and settings sections. For now, it's essential to understand how the settings and configurations set in this section affect the entire sketch. The codes written here establish fundamental rules applicable throughout the sketch. Additionally, the following methods are noteworthy:

**size()** - This function is used to configure the dimensions of our sketch. It needs to be in the first line of the setup code block and can be used in different forms, specifying width and height or adding a rendering engine parameter.
- size(width,height);
- size(width, height, renderer);

The width and height values could be given in pixels. Size function accepts a third parameter, renderer, which is used to set which rendering engine our sketch will use. By default, the renderer is set to P2D. The available renderers are P2D (Processing 2D), P3D (Processing 3D, should be used if your sketches will include 3D graphics) and PDF (2D graphics are drawn directly into an Acrobat PDF file. More inforation can be found [here](https://processing.org/reference/libraries/pdf/)). P2D and P3D renderers make use of OpenGL compatible graphics hardware.

**fullScreen()** - As of Processing 3.0, fullScreen function can now be used instead of the size() function. Just like the size() function, it should be in the first line of the setup block as well. The usage is as follows:

- fullScreen();
- fullScreen(display);
- fullScreen(renderer);
- fullScreen(display, renderer);

If you use it without any parameters, your processing sketch will simply run in fullscreen, and will run on your main display. The ‘display’ parameter is used to set on which display your sketch will run. For example if you connect external monitors to your computer, you can set the display variable to 2 (or 3, 4 etc.) and your sketch will run there. The ‘renderer’ parameter is as explained at the size() part above.
### **Settings Block**
This is another feature that is introduced with the new release of Processing. It is a code block, just like setup and draw. It is useful when you want to define size() or fullScreen() methods with variable parameters. It is also necessary to define size() and other styling properties such as smooth() in this code block if you are using any environment other than Processing’s own IDE, such as Eclipse. But you will not be needing it in most cases, definitely not in this article.
### **Draw Block**
There is nothing special to talk about the draw block, yet everything is special about it. Draw block is where all the magic happens. It is the heart of your program, beating 60 times a second. This code block houses all your code logic. All your shapes, objects etc. will be written in here.

Most of the code we will talk about in this article is going to be from the draw block, so it is important that you clearly understand how this code block works. To give you a demonstration, here is something you can try. First note that we can print anything to the console by using the print() or println() methods. Print methods only print to the console, println however prints and appends a newline at the end, so each println() will print in separate rows.

So, take a look at the following code block. First, try to guess what it will print in the console. Then, go ahead and try it out:

    void setup(){

    }void draw(){

    `  `int x = 0;

    `  `x += 1;

    `  `print(x+" ");

    }

If you guessed “1 2 3 4…”, I got you! This is one of the confusions in Processing. Remember this block repeatedly gets executed? When you define a variable here, it gets defined on each loop over and over again. On each iteration, x is set to 0, gets incremented by 1 and gets printed to the console. Therefore we get the result “1 1 1 1…”. This example was somewhat obvious, but it may be confusing when things get a little complicated.

We don’t want x to get overwritten, so how can we achieve this and get the result “1 2 3 4…” ? By using global variables. This is nothing fancy, we only define the variable outside of draw block so it doesn’t get re-defined on each iteration. Also, the scope of the variable will be reachable throughout the sketch. See the code below:

    int x = 0;

    void setup(){

    }void draw(){

    `  `x += 1;

    `  `print(x+" ");

    }

You might be asking yourself, how can a variable defined outside of our blocks work? And why didn’t we use the setup() block since it gets executed once at the beginning? The answer is related with object-oriented programming and scopes, if you are not familiar, you may skip this paragraph. Remember how they get wrapped with a Java class? The variables we write outside of setup() and draw() block also gets wrapped, therefore they are treated as fields of the outer class that wraps our code. Using x+=1 is the same as using this.x+=1. It also functions the same in our case, no variable called x is defined in the scope of draw() and an outer scope is searched, which is the scope of this. And why didn’t we define our variable x in the setup() section? If we did, the scope of which x is defined would be the scope of the setup function and it wouldn’t be accessible from the draw() block.
### Drawing Shapes & Texts
<img style="float: center;" width=100% src="image/idi1.jpg">

Now we know how to configure our sketch using the setup block, and You know what draw block does. Before you begin, you should understand the coordinate system. In Processing, you determine the coordinates of every object you draw on the screen. The coordinate system is in pixels. The origin (ie. starting point) is the top left corner, you should give your coordinates relative to that point. Another thing you should know is, each shape has a different reference point. For example, rect() has its top left corner as a reference point. For ellipse(), it is the center. These reference points can be changed with methods like rectMode() and ellipseMode(), which I will be explaining in the properties & settings section. An example figure is provided to help you understand better.

This article is a basic overview of Processing, so we will not be touching any complex shapes like vertexes or 3D shapes. Basic 2D shapes will actually be more than enough for us to create our own game. In the figure, you can see examples of how shapes are drawn. Each shape has its own syntax to be created, but the basic idea is to give either its coordinates or its sizes or both. Here are some shapes you should be familiar with (for all values given below, ‘x’ and ‘y’ means x and y coordinates in pixels, ‘w’ and ‘h’ means width and height values also in pixels):

point() - Simple point, only needs a single coordinate. Usage:

- point(x, y)
- point(x, y, z) - In case you are using 3 dimensions.

line() - For creating a line. You can create a line with only a starting and ending point. Usage:

- line(x1, y1, x2, y2)
- line(x1, y1, z1, x2, y2, z2) - In case you are using 3 dimensions.

triangle() - For creating a triangle. Usage: triangle(x1, y1, x2, y2, x3, y3)

quad() - For creating a quadrilateral. Usage: quad(x1, y1, x2, y2, x3, y3, x4, y4)

rect() - For creating a rectangle. The reference point is top left corner by default (refer to the figure). Here is the usage:

- rect(x, y, w, h)
- rect(x, y, w, h, r) - ‘r’ mean the radius in pixels to make the corners rounded.
- rect(x, y, w, h, tl, tr, br, bl) - Radius for top left, top right, bottom right, bottom left corners respectively. This is also in pixels.

ellipse() - For creating an ellipse shape. This is also used to create a circle, same width and height values should be given. The reference point for this shape is the center by default (refer to the figure). Here is the usage:

- ellipse(x, y, w, h)

arc() - Draw an arc. Usage:

- arc(x, y, w, h, start, stop) - ‘start’ and ‘stop’ is used to determine the angle to start and stop drawing the arc. Values are in radians. Constants such as “PI, HALF\_PI, QUARTER\_PI and TWO\_PI” can be used.
- arc(x, y, w, h, start, stop, mode) - ‘mode’ variable is to determine the rendering style of the arc (string). Available options are “OPEN, CHORD, PIE”. OPEN will leave the non-drawn parts borderless. CHORD will complete the non-drawn parts with a border. PIE will make your arc look like a pie chart.

Displaying texts on the screen is similar to displaying shapes, the basic idea is that you determine a coordinate at which you want your text to be displayed. There is however more to handling texts. You will have more control over your texts after the properties & settings section, where you’ll learn how to apply settings and properties to objects. For now, I will show the basics of displaying texts. There are many ways to do it, I’ll only show the essentials.

text() - Display texts. Usage:

- text(c, x, y) - ‘c’ means character, any alphanumeric character will be displayed.
- text(c, x, y, z) - In case you are working with 3 dimensions.
- text(str, x, y) - ‘str’ is the string to be displayed.
- text(str, x, y, z) - In case you are working with 3 dimensions.
- text(num, x, y) - ‘num’ is the numeric value to be displayed.
- text(num, x, y, z) - In case you are working with 3 dimensions.
### **Properties & Settings**
First thing that should be explained in this section would be the logic behind setting properties of objects. Fill color, background color, border, border width, border color, alignment of the shapes, border styles etc. could be some examples of these properties.

When you set a property, you have to remember that the code will be executing from top to bottom. Say, you set the “fill” property to red, all the objects drawn below that line will be filled with red until it gets overwritten by another fill property. Same thing applies for other properties as well, however note that not all properties will overwrite each other. For example “stroke” property doesn’t overwrite “fill” property, instead they work together. 

**fill()** - Sets the fill color to objects. This setting is also used to color texts. For now, we only need to know the following usage:

- fill(r, g, b) - Red, green and blue values as integer
- fill(r, g, b, a) - Additional alpha value, max is 255

**noFill()** - Sets the fill color to transparent.

stroke() - Sets the stroke color to objects. Stroke property is applicable for lines and borders around objects. For now, we only need to know the following usage:

- stroke(r, g, b) - Red, green and blue values as integer.
- stroke(r, g, b, a) - Additional alpha value, max is 255

**noStroke()** - Removes the stroke.

**strokeWeight()** - Sets the width of the stroke. Usage:

- strokeWeight(x) - x is an integer and represents the width of stroke in pixels.

**background()** - Sets the background color. For now, we only need to know the following usage:

- background(r, g, b) - Red, green and blue values as integer.
- background(r, g, b, a) - Additional alpha value, max is 255
#### Alignment Settings
**ellipseMode()** - Sets where to take as reference point aligning ellipses. Usage:

- **ellipseMode(mode)** - ‘mode’ is the parameter, here are the available parameters: 
  - CENTER (default): Take the center as the reference point.
  - RADIUS: This also takes the center as a the reference point, but in this mode, the w and h values you specify are treated as half (ie. radius instead of diameter)
  - CORNER: Takes top left corner as a reference point.
  - CORNERS: Sets the first two parameters (x and y) as the location of the top-left corner, and last two parameters (w and h) as the location of the bottom left corner of the ellipse. So this mode, “width” and “height” is irrelevant. Thinking it as ellipse(x\_tl,y\_tl,x\_br,y\_br) makes more sense in this case.

**rectMode()** - Sets where to take as reference point aligning rectangles. Usage:

- **rectMode(mode)** - ‘mode’ is the parameter, here are the available parameters: 
  - CENTER: Take the center as the reference point.
  - RADIUS: This also takes the center as a the reference point, but in this mode, the w and h values you specify are treated as half
  - CORNER (default): Takes top left corner as a reference point.
  - CORNERS: Sets the first two parameters (x and y) as the location of the top-left corner, and last two parameters (w and h) as the location of the bottom left corner of the ellipse. So this mode, “width” and “height” is irrelevant. Thinking of it as rect(x\_tl,y\_tl,x\_br,y\_br) makes more sense in this case.
#### Text Related Settings
**textSize()** - Sets the font size of text. Usage:

- textSize(size) - Integer value of the desired size.

**textLeading()** - Sets the line height of your texts. Usage:

- **textLeading(lineheight)** - Pixel value of the space between lines.

**textAlign()** - Sets where to take as reference point aligning texts. Usage.

- textAlign(alignX) - ‘alignX’ is for horizontal alignment. Available: LEFT, CENTER, RIGHT
- textAlign(alignX, alignY) - ‘alignY’ is for vertical alignment. Available: TOP, BOTTOM, CENTER, BASELINE.
### **Animations**
` `How to make objects move? Simple, instead of giving coordinates as integers, You use variables so that you can increment / decrement them. Make sense? Take a look at the following code:

    // initialize x and y as 0int x=0;int y=0;

    void setup(){

    `  `size(800,600);

    `  `background(255); // set background color to white

    }

    void draw(){

    `  `fill(255,0,0); // fill color red

    `  `stroke(0,0,255); // stroke color blue

    `  `ellipseMode(CENTER); // ref. point to ellipse is its center



    `  `ellipse(x, y, 20, 20); // draw the ellipse



    `  `// increment x and y

    `  `x+=5;

    `  `y+=5;

    }

You set x and y as global variables and their initial value to 0. In our draw loop, you created you ellipse, set the fill color to red, stroke color to blue and coordinates to x and y. When we increment x and y, the ball simply changes its location. 

` `Each time the draw block iterates, x and y gets incremented by 5 and therefore the ball gets redrawn to 5 pixels down and right. However the ball is drawn from the previous iterations remain in the view. To get rid of the marks the ball leaves behind, you simply remove the background(255) from setup block, and paste it to be the very first line of the draw block. When you background code was in the setup block, it ran one time at the beginning, making your background white. But that isn’t enough, you need it to set your background to white on each loop to cover the balls drawn from the previous loops. Background being the first line means it runs first, it becomes the base layer. On each loop, our canvas is painted white, and new elements gets drawn on top of the white background. So you have no marks.

That is the idea behind animating things in Processing, manipulating the objects’ coordinates programmatically to change their location.  
### **Keyboard & Mouse Interactions**
Keyboard & mouse interactions in Processing are very easy and straightforward. There are methods you can call for each event, and what you write inside will be executed once when the event occurs. Also there are global variables such as mousePressed and keyPressed you can use in your draw block to take advantage of the loop. Here are some of the methods with explanations:

    void setup() {

    `  `size(500, 500);

    }

    void draw() {

    `  `if (mousePressed) {

    `    `// Codes here will be executed as long as the mouse

    `    `// button is pressed



    `    `if (mouseButton == LEFT){

    `      `// This lines will be executed as long as

    `      `// the clicked mouse button is the left mouse

    `      `// button.

    `    `}

    `  `}

    `  `if (keyPressed) {

    `    `// Codes here will be executed as long as a key

    `    `// on the keyboard is pressed



    `    `if (key == CODED) {

    `      `// This if statement checks if the pressed key

    `      `// is recognised by Processing.



    `      `if (keyCode == ENTER) {

    `        `// This lines will be executed if the pressed key

    `        `// is the enter key.

    `      `}

    `    `}

    `    `else{

    `      `// This lines will be executed if the pressed key

    `      `// is not recognised by processing.

    `    `}

    `  `}



    }

    void mousePressed() {

    `  `// These codes will be executed once, when mouse

    `  `// is clicked. Note that mouseButton variable is

    `  `// also be used here.

    }

    void keyPressed() {

    `  `// These codes will be executed once, when a key

    `  `// is pressed. Note that key and keyCode variables

    `  `// are also usable here.

    }

As you can see, it is pretty easy to check whether the mouse is clicked or which key is being pressed. There are however more options available for mousePressed and keyCode variables. Available options for mousePressed are LEFT, RIGHT and CENTER. There are many more available for keyCode; UP, DOWN, LEFT, RIGHT, ALT, CONTROL, SHIFT, BACKSPACE, TAB, ENTER, RETURN, ESC and DELETE.

One thing to know about the mouse variables, and we will use this a lot, is how to get the coordinates of the mouse. To get the exact coordinates of the cursor, you can use mouseX and mouseY variables directly in the draw() block. 

**Other Related Programming languages!**

**p5.js:**

The official website for Processing is <https://p5js.org/>

It  is a JavaScript library that brings the simplicity and power of Processing to the web. It provides a creative coding platform for artists, designers, and developers to create interactive graphics, animations, and visualizations directly in web browsers. p5.js is designed to be beginner-friendly, making it accessible for those without a strong programming background.

One of the main goals of p5.js is to enable artists and designers to express their creativity through code. It employs a simple and intuitive syntax, similar to Processing, allowing users to focus on the visual and interactive aspects of their projects. The library provides a wide range of functions and features for handling graphics, user input, and animations.

p5.js is built on top of the HTML5 canvas element, which allows for the rendering of 2D graphics in web browsers. It also supports WebGL, enabling the creation of high-performance 3D graphics and visualizations. The library provides a set of drawing functions to create shapes, manipulate colors, and work with pixels.

Interactivity is a key aspect of p5.js. It allows users to respond to user input from mouse, keyboard, touch, or other devices. This enables the creation of interactive experiences where visuals and animations react to user actions. Additionally, p5.js supports working with sound, video, and external data sources, enabling the integration of multimedia elements into projects.

p5.js is designed to be portable and shareable. Projects created with p5.js can be easily shared and embedded in websites, making them accessible to a wide audience. The library has an active and supportive community that shares examples, tutorials, and resources, fostering learning and collaboration.

With its focus on simplicity, accessibility, and web compatibility, p5.js is an excellent choice for artists, designers, and educators who want to create interactive web-based visual projects. Whether it's creating interactive art, data visualizations, or browser-based games, p5.js provides a powerful and intuitive platform for creative expression through code.

**Cinder:**

The official website for Cinder is <https://libcinder.org/>

It is a C++ framework that focuses on creative coding and graphics. It provides a powerful platform for creating interactive installations, visualizations, and multimedia projects. Cinder is known for its emphasis on performance, flexibility, and the ability to create visually stunning applications.

One of the primary goals of Cinder is to provide a framework that enables developers to work with graphics and multimedia in a straightforward manner. It offers a wide range of features and libraries for handling graphics, audio, input/output, and more. Cinder provides a unified interface for working with various media formats, making it easier to integrate different types of media into projects.

Cinder emphasizes performance and efficiency, making it suitable for real-time applications and projects that require high-quality visuals. It leverages modern graphics technologies, such as OpenGL, to achieve hardware-accelerated rendering and take advantage of the capabilities of modern GPUs. This enables developers to create visually rich and interactive experiences.

Flexibility is another key aspect of Cinder. It provides a modular architecture that allows developers to choose and integrate the specific libraries and components they need for their projects. This flexibility enables developers to tailor Cinder to their specific requirements, whether it's creating interactive art installations, data visualizations, or multimedia applications.

Cinder has a thriving and supportive community of artists, designers, and developers who actively contribute to its development and share their projects and knowledge. The community provides resources, tutorials, and examples, making it easier for newcomers to get started with the framework and learn from others' experiences.

Overall, Cinder offers a robust toolkit for creative coding and multimedia projects. Its focus on performance, flexibility, and high-quality graphics makes it a popular choice for developers who want to create visually compelling and interactive experiences. Whether you're working on interactive installations, multimedia applications, or visualizations, Cinder provides the tools and capabilities to bring your creative ideas to life.

**OpenFrameworks:**

The official website for OpenFrameworks is <https://openframeworks.cc/>

It is a powerful C++ toolkit designed for creative coding and multimedia projects. It provides a wide range of libraries and tools that enable artists, designers, and developers to create interactive installations, visualizations, and multimedia applications.

One of the main strengths of OpenFrameworks is its versatility. It offers a comprehensive set of libraries and addons that cover various aspects of creative coding, including graphics, audio, computer vision, networking, and more. These libraries make it easier to work with different media types and integrate them into projects.

OpenFrameworks is known for its accessibility and user-friendly approach. It provides a simplified syntax and a consistent API that makes it easier for artists and designers to start coding and experimenting with creative ideas. The framework abstracts away many low-level details, allowing developers to focus on the artistic and interactive aspects of their projects.

Another notable feature of OpenFrameworks is its active and vibrant community. The community contributes to the development of the framework, shares knowledge, and creates addons and examples that extend the capabilities of OpenFrameworks. This collaborative environment provides a wealth of resources, tutorials, and support for newcomers and experienced developers alike.

OpenFrameworks is cross-platform, which means it works on multiple operating systems such as Windows, macOS, and Linux. This allows developers to create projects that can run on different platforms without significant modifications. Additionally, OpenFrameworks integrates well with other popular tools and frameworks, making it compatible with existing workflows and technologies.

The flexibility of OpenFrameworks enables a wide range of applications, from interactive art installations to real-time visualizations and multimedia experiences. Its extensive library ecosystem and community support make it a popular choice for artists, designers, and developers who want to explore the possibilities of creative coding and multimedia projects.

Overall, OpenFrameworks provides a powerful and accessible toolkit for creative coding. Its versatility, simplicity, and collaborative community make it an excellent choice for those interested in pushing the boundaries of interactive media and exploring new possibilities in artistic expression.

**Max/MSP:**

The official website for Max/MSP is <https://cycling74.com/products/max/>

It is a visual programming language and development environment primarily used for music, multimedia, and interactive projects. It allows users to create interactive systems by visually connecting objects (called "objects" or "boxes") together in a graphical interface.

One of the key features of Max/MSP is its visual approach to programming. Instead of writing code in a traditional text-based programming language, users create programs by arranging and connecting objects in a visual workspace. Each object represents a specific function or process, and the connections between objects define the flow of data and control.

Max/MSP is particularly well-suited for real-time audio processing and interactive visualizations. It provides a rich set of built-in objects for audio synthesis, signal processing, and MIDI control. Users can create complex musical compositions, design interactive sound installations, and manipulate audio and video in real-time.

The visual nature of Max/MSP makes it accessible to users with different levels of programming experience. It allows for rapid prototyping and experimentation, as changes to the visual program can be made in real-time. Additionally, Max/MSP offers extensive documentation, tutorials, and a supportive user community, making it easier for newcomers to get started and learn from others.

Max/MSP also supports integration with external hardware and software through various protocols and interfaces. This allows users to connect and control external devices, sensors, and software applications, expanding the possibilities of interactive and multimedia projects.

Max/MSP is often used in the fields of music composition, live performance, interactive installations, and multimedia art. Its visual programming paradigm and focus on real-time audio and visual processing make it a powerful tool for creating dynamic and interactive experiences.

Overall, Max/MSP provides a unique and intuitive approach to programming, making it accessible to artists, musicians, and designers who want to create interactive multimedia projects without extensive coding knowledge. Its visual nature, real-time capabilities, and extensive library of objects make it a versatile and powerful tool for exploring the intersection of music, visuals, and interactivity.

**TouchDesigner:**

The official website for TouchDesigner is <https://www.derivative.ca/>

It is a node-based visual programming environment that enables the creation of interactive installations, visualizations, and live performances. It provides a graphical interface for connecting and manipulating various multimedia components such as video, audio, 3D, and more.

One of the key features of TouchDesigner is its node-based workflow. Users create programs by connecting nodes together in a network, where each node represents a specific function or process. These nodes can represent video sources, effects, audio processors, control parameters, or any other element of a multimedia project. The connections between nodes define the flow of data and control within the program.

TouchDesigner excels in real-time visual processing and manipulation. It offers a wide array of tools and libraries for working with video, including real-time video playback, compositing, blending, and effects. It also supports advanced 3D rendering capabilities, allowing users to create and manipulate 3D objects, textures, and lighting effects in real-time.

Interactivity is a core aspect of TouchDesigner. It provides various means for users to respond to user input, such as mouse and keyboard events, MIDI controllers, sensors, and external devices. This allows for the creation of interactive experiences where visuals and effects can react and respond to user actions in real-time.

TouchDesigner supports integration with external devices and protocols, making it suitable for controlling and communicating with other hardware and software systems. It has extensive support for protocols like OSC (Open Sound Control) and DMX (Digital Multiplex), enabling users to connect and control external devices, lighting systems, and other interactive components.

TouchDesigner has a strong community of artists, designers, and developers who actively contribute to its development and share their projects and knowledge. The community provides resources, tutorials, and workshops, making it easier for newcomers to learn and explore the capabilities of TouchDesigner.

Overall, TouchDesigner provides a powerful and flexible platform for creating interactive multimedia projects. Its node-based visual programming approach, real-time visual processing capabilities, and support for interactivity make it a popular choice for artists, designers, and performers who want to create immersive and dynamic visual experiences.

**Unity:**

The official website for Unity is <https://unity.com/>

It** is a powerful and widely-used game development engine and platform. It provides a comprehensive set of tools and features for creating interactive 2D and 3D experiences across various platforms, including desktop, mobile, console, and virtual reality.

One of the key features of Unity is its user-friendly interface and intuitive workflow. It offers a visual editor that allows developers to create and manipulate game objects, scenes, and assets without the need for extensive coding. The editor provides a wide range of tools for designing levels, creating animations, implementing physics, and managing assets, making game development accessible to both beginners and experienced developers.

Unity supports a wide range of platforms, including Windows, macOS, iOS, Android, Xbox, PlayStation, and many others. This cross-platform compatibility allows developers to create games and applications that can be deployed and run on multiple devices and operating systems with minimal modifications.

The engine provides a powerful scripting API based on C#, allowing developers to write custom code to implement game logic and behavior. It also supports visual scripting through tools like Bolt and Playmaker, which enable developers to create game mechanics and interactions using a node-based system without writing code.

Unity offers a vast asset store where developers can find a wide variety of pre-made assets, scripts, and plugins to enhance their projects. This allows for rapid prototyping and accelerates the development process by providing ready-to-use resources for graphics, sound, animations, and more.

Another notable feature of Unity is its support for real-time rendering and advanced graphics capabilities. It includes a powerful rendering engine that supports modern rendering techniques like physically-based rendering (PBR), dynamic lighting, and post-processing effects. This enables developers to create visually stunning and realistic games and simulations.

Unity also provides a range of additional features, such as built-in physics simulation, audio mixing, networking, and support for augmented reality (AR) and virtual reality (VR) experiences. These features expand the possibilities for creating immersive and interactive content.

Overall, Unity is a versatile and widely-used game development engine that empowers developers to create interactive experiences across various platforms. Its user-friendly interface, cross-platform compatibility, extensive asset store, and advanced graphics capabilities make it a popular choice for game developers, interactive media creators, and virtual reality designers.

**Practical Works:**

**Practice 1:**

**Graphical Visual Display:**
<br>

[Source](https://gist.github.com/oguzgelal/13d2e0b1cd98b62c3986)
<br>
<br>
The Following Processing sketch creates an animated visual display featuring four moving ellipses on a canvas. Each ellipse has a unique color and follows a specific trajectory on the screen. The movement of the ellipses is controlled by their individual speeds, and the direction may change based on the condition of the mouse button being pressed. If the mouse button is not pressed, the ellipses continue their animated motion.

**Ellipses:** There are four ellipses drawn on the canvas, each defined by its own set of variables for position (x, y), speed, and color.

**Motion:** The ellipses move continuously based on their designated speeds, creating dynamic patterns on the canvas.

**Colors:** Each ellipse is filled with a distinct color determined by its RGB values.

**Mouse Interaction:** The animation behavior may change when the mouse button is released. The mouseReleased function resets the positions of the ellipses, and the draw function adjusts their trajectories accordingly.

**Initialization:** The initial positions of the ellipses are set using the setStartingPoints function, contributing to the overall visual arrangement.

<video width=100% controls><source src="image/prv.mp4" type="video/mp4">

    int x1, y1;

    int x2, y2;

    int x3, y3;

    int x4, y4;

    int b1Speed=4;

    int b2Speed=1;

    int b3Speed=6;

    int b4Speed=2;

    int b1r=255, b1g=120, b1b=200;

    int b2r=0, b2g=220, b2b=0;

    int b3r=30, b3g=150, b3b=110;

    int b4r=50, b4g=100, b4b=75;

    void setup() {

    `  `size(500, 500);

    `  `setStartingPoints();

    }

    void draw() {

    `  `background(255);

    `  `stroke(0);

    `  `ellipseMode(CENTER);



    `  `fill(b1r, b1g, b1b);

    `  `ellipse(x1, y1, 20, 20);

    `  `fill(b2r, b2g, b2b);

    `  `ellipse(x2, y2, 20, 20);

    `  `fill(b3r, b3g, b3b);

    `  `ellipse(x3, y3, 20, 20);

    `  `fill(b4r, b4g, b4b);

    `  `ellipse(x4, y4, 20, 20);

    `  `if (!mousePressed) {

    `    `x1+=b1Speed; 

    `    `y1+=b1Speed;

    `    `x2-=b2Speed; 

    `    `y2+=b2Speed;

    `    `x3+=b3Speed; 

    `    `y3-=b3Speed;

    `    `x4-=b4Speed; 

    `    `y4-=b4Speed;

    `  `}

    }

    void mouseReleased() {



    `  `setStartingPoints();

    }

    void setStartingPoints() {

    `  `x1=0;

    `  `y1=0;

    `  `x2=width;

    `  `y2=0;

    `  `x3=0;

    `  `y3=height;

    `  `x4=width;

    `  `y4=height;

    }

**Practice 2:**

**reachSegment:**

[Source](https://processing.org/examples/reach3.html)

The Following Processing sketch creates a visually dynamic and interactive scene involving a series of connected segments forming a flexible arm that reaches towards a moving target. Additionally, a bouncing ball adds an element of animation to the composition. 

**Arm Segments:** The arm is composed of multiple segments connected in a chain. Each segment is represented by a line, and their collective movement resembles the behavior of a flexible structure.

**Ball Animation:** A bouncing ball moves within the canvas, reflecting off the edges. The ball's position is updated in each frame, and its direction is reversed when it reaches the canvas boundaries.

**Interaction:** The position of the arm segments is influenced by the ball's movement. The arm dynamically adjusts its configuration to reach towards the ball as it bounces around the canvas.

**Functionality:**

reachSegment: Calculates the angle and position for each segment of the arm to reach towards a specified target point (in this case, the ball's position).

**positionSegment:** Updates the position of each arm segment based on the cosine and sine of its angle and the predefined segment length.

**segment:** Draws each arm segment as a line with varying stroke weights.

**Setup and Draw Functions:** The setup function initializes the canvas size, stroke properties, and initial positions for the arm segments. The draw function is called continuously and handles the animation, updating the ball's position, calculating arm segment positions, and drawing the scene.

<video width=100% controls><source src="image/prv1.mp4" type="video/mp4">


    int numSegments = 8;

    float[] x = new float[numSegments];

    float[] y = new float[numSegments];

    float[] angle = new float[numSegments];

    float segLength = 26;

    float targetX, targetY;

    float ballX = 50;

    float ballY = 50;

    int ballXDirection = 1;

    int ballYDirection = -1;

    void setup() {

    `  `size(640, 360);

    `  `strokeWeight(20.0);

    `  `stroke(255, 100);

    `  `noFill();

    `  `x[x.length-1] = width/2;     

    `  `y[x.length-1] = height;  

    }

    void draw() {

    `  `background(0);

    `    `strokeWeight(20);

    `  `ballX = ballX + 1.0 \* ballXDirection;

    `  `ballY = ballY + 0.8 \* ballYDirection;

    `  `if(ballX > width-25 || ballX < 25) {

    `    `ballXDirection \*= -1; 

    `  `}

    `  `if(ballY > height-25 || ballY < 25) {

    `    `ballYDirection \*= -1; 

    `  `}

    `  `ellipse(ballX, ballY, 30, 30);

    `  `reachSegment(0, ballX, ballY);

    `  `for(int i=1; i<numSegments; i++) {

    `    `reachSegment(i, targetX, targetY);

    `  `}

    `  `for(int i=x.length-1; i>=1; i--) {

    `    `positionSegment(i, i-1);  

    `  `} 

    `  `for(int i=0; i<x.length; i++) {

    `    `segment(x[i], y[i], angle[i], (i+1)\*2); 

    `  `}

    }

    void positionSegment(int a, int b) {

    `  `x[b] = x[a] + cos(angle[a]) \* segLength;

    `  `y[b] = y[a] + sin(angle[a]) \* segLength; 

    }

    void reachSegment(int i, float xin, float yin) {

    `  `float dx = xin - x[i];

    `  `float dy = yin - y[i];

    `  `angle[i] = atan2(dy, dx);  

    `  `targetX = xin - cos(angle[i]) \* segLength;

    `  `targetY = yin - sin(angle[i]) \* segLength;

    }

    void segment(float x, float y, float a, float sw) {

    `  `strokeWeight(sw);

    `  `pushMatrix();

    `  `translate(x, y);

    `  `rotate(a);

    `  `line(0, 0, segLength, 0);

    `  `popMatrix();

    }

**Human-Computer Interaction (HCI)" and "Sensor Technologies**
**Human-Computer Interaction (HCI):**

` `Human-Computer Interaction (HCI) is a multidisciplinary field that studies the design and use of computer technology, focusing on creating effective and user-friendly interactions between humans and computers. The goal of HCI is to enhance the usability and accessibility of computer systems, making them more intuitive, efficient, and enjoyable for users. HCI encompasses a range of design principles, usability testing, and user-centered methodologies to create interfaces that cater to human needs and behaviors. Examples of HCI include graphical user interfaces (GUIs), touchscreens, voice recognition, and gesture-based interactions.

**Sensor Technologies:**

` `Sensor technologies involve the use of devices capable of capturing physical data from the environment and converting it into a form that computers can interpret. Sensors are essential components in various applications, providing input for automation, monitoring, and control systems. These technologies span a wide range, including motion sensors, temperature sensors, pressure sensors, and more. In the context of human-computer interaction, sensors like those found in Kinect and Leap Motion allow computers to detect and interpret human movements, enabling gesture-based control and immersive experiences. Sensors play a crucial role in the Internet of Things (IoT), where they collect data from the physical world and contribute to the interconnected web of devices and systems. Here are some examplse:

**Kinect:**

` `The Kinect is a motion-sensing input device developed by Microsoft. It was originally released in 2010 as an accessory for the Xbox 360 gaming console and later evolved with newer versions. 

**1. Hardware Components:**

`   `**- Cameras:** Kinect utilizes a combination of cameras to capture visual data. The first-generation Kinect included an RGB camera capable of capturing color images and a depth sensor camera that calculated the distance of objects from the sensor.

`   `**- Microphone Array:** Kinect includes an array of microphones that enable voice recognition and audio input.

**2. Motion Tracking:**

`   `**- Depth Sensing:** One of the key features of Kinect is its depth sensing capability. It uses structured light or time-of-flight technology to calculate the distance between the sensor and objects in the environment. This allows for accurate tracking of the user's movements in three-dimensional space.

`   `**- Skeletal Tracking:** Kinect can track the user's body movements and gestures by analyzing the depth data. It can recognize joint positions and skeletal structures, enabling more immersive and natural interaction with games and applications.

`   `- **Facial Recognition:** Kinect is also capable of facial recognition, allowing it to detect and track the user's face. This feature can be utilized for various applications, such as personalized experiences or user identification.

**3. Software and Applications:**

`   `- **Gaming:** Kinect was initially introduced as a gaming device, offering controller-free gaming experiences. It enabled users to control games using their body movements, voice commands, and gestures.

`   `- **Motion Capture:** Kinect's accurate motion tracking capabilities made it popular in the field of motion capture. It allowed developers and animators to capture real-time human movements and transfer them to virtual characters for games, films, and other applications.

`   `- **Healthcare and Rehabilitation:** Kinect found applications in the healthcare industry, particularly in physical therapy and rehabilitation. Its motion tracking features enabled the development of interactive exercises and therapy programs.

`   `**- Robotics and Computer Vision**: Kinect's depth sensing capabilities made it valuable in robotics and computer vision research. It allowed robots to perceive and navigate their surroundings using real-time depth information.

**4. Evolution and Discontinuation:**

`   `- Microsoft released the second-generation Kinect in 2013, improving upon the original version's capabilities and introducing enhanced features.

`   `- However, in October 2017, Microsoft announced that it would discontinue manufacturing the Kinect, shifting its focus to other technologies.

`   `- While Kinect devices are no longer being produced, their impact on the field of motion sensing and interactive technology remains significant.

**Leap Motion:**

Leap Motion is a hand-tracking motion controller that allows users to interact with computers and virtual reality environments using natural hand and finger movements. Here's a detailed description of Leap Motion:

**1. Hardware Components:**

`   `**- Infrared Cameras:** Leap Motion utilizes a set of infrared cameras and sensors to capture the movements of the user's hands and fingers. These cameras create a three-dimensional view of the hand in real-time.

`   `**- LED Lights:** The Leap Motion controller includes infrared LED lights that illuminate the hand, making it easier for the cameras to track the movements.

**2. Hand Tracking:**

`   `**- Finger and Hand Recognition:** Leap Motion can track individual fingers and the shape of the hand with high precision. It can detect and recognize various hand gestures, such as pointing, grabbing, and swiping.

`   `**- Sub-Millimeter Accuracy:** Leap Motion boasts sub-millimeter accuracy, enabling precise tracking of hand and finger movements. This allows for fine-grained control and interaction with virtual objects or applications.

`   `**- Real-Time Tracking:** The hand tracking is performed in real-time, providing immediate feedback and responsiveness to the user's movements.

**3. Software and Applications:**

`   `**- Interaction and Control:** Leap Motion provides a software development kit (SDK) that allows developers to create applications and experiences utilizing hand tracking. Users can control software and interact with digital content by moving their hands and fingers in the air.

`   `**- Virtual Reality Integration:** Leap Motion has been integrated into virtual reality headsets, enhancing the immersive experience by enabling users to see and interact with their own hands in the virtual environment.

`   `**- Gestural Input:** Leap Motion recognizes a wide range of gestures, allowing users to perform actions such as grabbing, swiping, pinching, and releasing. These gestures can be mapped to various interactions within applications.

`   `**- Education and Simulation:** Leap Motion has found applications in education and training, such as virtual anatomy lessons or simulations for surgery training. The precise hand tracking allows for detailed manipulation of virtual objects.

**4. Development and Community:**

`   `- Leap Motion provides an active developer community and resources to support the creation of applications utilizing their technology. This includes documentation, tutorials, and forums for developers to share their experiences and collaborate.

`   `**- Integration with Other Technologies:** Leap Motion can be integrated with other technologies such as virtual reality headsets, augmented reality devices, and robotics, expanding its potential applications and use cases.

Leap Motion offers a unique and intuitive way for users to interact with digital content by tracking hand and finger movements with high precision. 

**Internet of Things (IoT) Platforms:**

`   `IoT platforms are part of the broader landscape of technologies related to the Internet of Things. They provide the infrastructure and tools to connect, manage, and extract insights from IoT devices. The term "IoT" encompasses a wide range of devices and systems that communicate and share data over the internet.
 
# **References:**

[Nextmaker](https://www.nexmaker.com/doc/11Interface-application-programming/processing.html)
<br> 

[Processing](https://processing.org)
<br>

[Developers](https://www.toptal.com/game/ultimate-guide-to-processing-the-fundamentals)
